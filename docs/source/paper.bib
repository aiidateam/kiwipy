@article{Jain2013,
author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin a.},
doi = {10.1063/1.4812323},
issn = {2166532X},
journal = {APL Materials},
number = {1},
pages = {011002},
title = {{The Materials Project: A materials genome approach to accelerating materials innovation}},
url = {http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\&Agg=doi},
volume = {1},
year = {2013}
}

@article{Talirz2020,
abstract = {Materials Cloud is a platform designed to enable open and seamless sharing of resources for computational science, driven by applications in materials modelling. It hosts 1) archival and dissemination services for raw and curated data, together with their provenance graph, 2) modelling services and virtual machines, 3) tools for data analytics, and pre-/post-processing, and 4) educational materials. Data is citable and archived persistently, providing a comprehensive embodiment of the FAIR principles that extends to computational workflows. Materials Cloud leverages the AiiDA framework to record the provenance of entire simulation pipelines (calculations performed, codes used, data generated) in the form of graphs that allow to retrace and reproduce any computed result. When an AiiDA database is shared on Materials Cloud, peers can browse the interconnected record of simulations, download individual files or the full database, and start their research from the results of the original authors. The infrastructure is agnostic to the specific simulation codes used and can support diverse applications in computational science that transcend its initial materials domain.},
archivePrefix = {arXiv},
arxivId = {2003.12510},
author = {Talirz, Leopold and Kumbhar, Snehal and Passaro, Elsa and Yakutovich, Aliaksandr V. and Granata, Valeria and Gargiulo, Fernando and Borelli, Marco and Uhrin, Martin and Huber, Sebastiaan P. and Zoupanos, Spyros and Adorf, Carl S. and Andersen, Casper W. and Sch{\"{u}}tt, Ole and Pignedoli, Carlo A. and Passerone, Daniele and VandeVondele, Joost and Schulthess, Thomas C. and Smit, Berend and Pizzi, Giovanni and Marzari, Nicola},
eprint = {2003.12510},
file = {:home/martin/Documents/academic/papers{\_}library/Talirz et al. - 2020 - Materials Cloud, a platform for open computational science.pdf:pdf},
pages = {1--22},
title = {{Materials Cloud, a platform for open computational science}},
url = {http://arxiv.org/abs/2003.12510},
year = {2020}
}

@article{Saal2013,
abstract = {High-throughput density functional theory (HT DFT) is fast becoming a powerful tool for accelerating materials design and discovery by the amassing tens and even hundreds of thousands of DFT calculations in large databases. Complex materials problems can be approached much more efficiently and broadly through the sheer quantity of structures and chemistries available in such databases. Our HT DFT database, the Open Quantum Materials Database (OQMD), contains over 200,000 DFT calculated crystal structures and will be freely available for public use at http://oqmd.org. In this review, we describe the OQMD and its use in five materials problems, spanning a wide range of applications and materials types: (I) Li-air battery combination catalyst/electrodes, (II) Li-ion battery anodes, (III) Li-ion battery cathode coatings reactive with HF, (IV) Mg-alloy long-period stacking ordered (LPSO) strengthening precipitates, and (V) training a machine learning model to predict new stable ternary compounds.},
author = {Saal, James E. and Kirklin, Scott and Aykol, Muratahan and Meredig, Bryce and Wolverton, Chris},
doi = {10.1007/s11837-013-0755-4},
file = {:home/martin/Documents/academic/papers{\_}library/Saal et al. - 2013 - Materials Design and Discovery with High-Throughput Density Functional Theory The Open Quantum Materials Database (.pdf:pdf},
isbn = {1047-4838},
issn = {1047-4838},
journal = {JOM},
month = {nov},
number = {11},
pages = {1501--1509},
title = {{Materials Design and Discovery with High-Throughput Density Functional Theory: The Open Quantum Materials Database (OQMD)}},
url = {http://link.springer.com/10.1007/s11837-013-0755-4},
volume = {65},
year = {2013}
}

@article{Curtarolo2012,
abstract = {Recent advances in computational materials science present novel opportunities for structure discovery and optimization, including uncovering of unsuspected compounds and metastable structures, electronic structure, surface, and nano-particle properties. The practical realization of these opportunities requires systematic generation and classification of the relevant computational data by high-throughput methods. In this paper we present Aflow (Automatic Flow), a software framework for high-throughput calculation of crystal structure properties of alloys, intermetallics and inorganic compounds. The Aflow software is available for the scientific community on the website of the materials research consortium, aflowlib.org. Its geometric and electronic structure analysis and manipulation tools are additionally available for online operation at the same website. The combination of automatic methods and user online interfaces provide a powerful tool for efficient quantum computational materials discovery and characterization. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1308.5715},
author = {Curtarolo, Stefano and Setyawan, Wahyu and Hart, Gus L. W. and Jahnatek, Michal and Chepulskii, Roman V. and Taylor, Richard H. and Wang, Shidong and Xue, Junkai and Yang, Kesong and Levy, Ohad and Mehl, Michael J. and Stokes, Harold T. and Demchenko, Denis O. and Morgan, Dane},
doi = {10.1016/j.commatsci.2012.02.005},
eprint = {1308.5715},
file = {:home/martin/Documents/academic/papers{\_}library/Curtarolo et al. - 2012 - AFLOW An automatic framework for high-throughput materials discovery.pdf:pdf},
isbn = {0927-0256},
issn = {09270256},
journal = {Computational Materials Science},
keywords = {AFLOW,Ab initio,Combinatorial materials science,High-throughput},
month = {jun},
pages = {218--226},
title = {{AFLOW: An automatic framework for high-throughput materials discovery}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0927025612000717},
volume = {58},
year = {2012}
}

@article{Draxl2019a,
abstract = {The Novel Materials Discovery (NOMAD) Laboratory is a user-driven platform for sharing and exploiting computational materials science data. It accounts for the various aspects of data being a crucial raw material and most relevant to accelerate materials research and engineering. NOMAD, with the NOMAD Repository, and its code-independent and normalized form, the NOMAD Archive, comprises the worldwide largest data collection of this field. Based on its findable accessible, interoperable, reusable data infrastructure, various services are offered, comprising advanced visualization, the NOMAD Encyclopedia, and artificial-intelligence tools. The latter are realized in the NOMAD Analytics Toolkit. Prerequisite for all this is the NOMAD metadata, a unique and thorough description of the data, that are produced by all important computer codes of the community. Uploaded data are tagged by a persistent identifier, and users can also request a digital object identifier to make data citable. Developments and advancements of parsers and metadata are organized jointly with users and code developers. In this work, we review the NOMAD concept and implementation, highlight its orthogonality to and synergistic interplay with other data collections, and provide an outlook regarding ongoing and future developments.},
author = {Draxl, Claudia and Scheffler, Matthias},
doi = {10.1088/2515-7639/ab13bb},
file = {:home/martin/Documents/academic/papers{\_}library/Draxl, Scheffler - 2019 - The NOMAD laboratory from data sharing to artificial intelligence.pdf:pdf},
issn = {2515-7639},
journal = {Journal of Physics: Materials},
keywords = {computational materials,data analytics,data repository,data science,metadata},
month = {may},
number = {3},
pages = {036001},
publisher = {IOP Publishing},
title = {{The NOMAD laboratory: from data sharing to artificial intelligence}},
url = {http://dx.doi.org/10.1088/2515-7639/ab13bb https://iopscience.iop.org/article/10.1088/2515-7639/ab13bb},
volume = {2},
year = {2019}
}

@article{Landis2012,
author = {Landis, David D. and Hummelshoj, Jens S. and Nestorov, Svetlozar and Greeley, Jeff and Dulak, Marcin and Bligaard, Thomas and Norskov, Jens K. and Jacobsen, Karsten W.},
doi = {10.1109/MCSE.2012.16},
issn = {1521-9615},
journal = {Computing in Science {\&} Engineering},
month = {nov},
number = {6},
pages = {51--57},
title = {{The Computational Materials Repository}},
url = {http://ieeexplore.ieee.org/document/6143910/},
volume = {14},
year = {2012}
}

@article{Jain2015a,
abstract = {The latest trends in high-performance computing systems show an increasing demand on the use of a large scale multicore systems in a efficient way, so that high compute-intensive applications can be executed reasonably well. However, the exploitation of the degree of parallelism available at each multicore component can be limited by the poor utilization of the memory hierarchy available. Actually, the multicore architecture introduces some distinct features that are already observed in shared memory and distributed environments. One example is that subsets of cores can share different subsets of memory. In order to achieve high performance it is imperative that a careful allocation scheme of an application is carried out on the available cores, based on a scheduling model that considers the main performance bottlenecks, as for example, memory contention. In this paper, the {\{}$\backslash$em Multicore Cluster Model{\}} (MCM) is proposed, which captures the most relevant performance characteristics in multicores systems such as the influence of memory hierarchy and contention. Better performance was achieved when a load balance strategy for a Branch-and-Bound application applied to the Partitioning Sets Problem is based on MCM, showing its efficiency and applicability to modern systems.},
archivePrefix = {arXiv},
arxivId = {1302.5679},
author = {Jain, Anubhav and Ong, Shyue Ping and Chen, Wei and Medasani, Bharat and Qu, Xiaohui and Kocher, Michael and Brafman, Miriam and Petretto, Guido and Rignanese, Gian-Marco and Hautier, Geoffroy and Gunter, Daniel and Persson, Kristin A.},
doi = {10.1002/cpe.3505},
eprint = {1302.5679},
file = {:home/martin/Documents/academic/papers{\_}library/Jain et al. - 2015 - FireWorks a dynamic workflow system designed for high-throughput applications.pdf:pdf},
isbn = {2007015102},
issn = {15320626},
journal = {Concurrency and Computation: Practice and Experience},
keywords = {Binary analysis,Call path profiling,Execution monitoring,Performance tools,Tracing,Workflows},
mendeley-tags = {Workflows},
month = {dec},
number = {17},
pages = {5037--5059},
pmid = {23335858},
title = {{FireWorks: a dynamic workflow system designed for high-throughput applications}},
url = {http://arxiv.org/abs/1302.5679 http://doi.wiley.com/10.1002/cpe.3505},
volume = {27},
year = {2015}
}


@article{Pizzi2016,
abstract = {Computational science has seen in the last decades a spectacular rise in the scope, breadth, and depth of its efforts. Notwithstanding this prevalence and impact, it is often still performed using the renaissance model of individual artisans gathered in a workshop, under the guidance of an established practitioner. Great benefits could follow instead from adopting concepts and tools coming from computer science to manage, preserve, and share these computational efforts. We illustrate here our paradigm sustaining such vision, based around the four pillars of Automation, Data, Environment, and Sharing. We then discuss its implementation in the open-source AiiDA platform (http://www.aiida.net), that has been tuned first to the demands of computational materials science. AiiDA's design is based on directed acyclic graphs to track the provenance of data and calculations, and ensure preservation and searchability. Remote computational resources are managed transparently, and automation is coupled with data storage to ensure reproducibility. Last, complex sequences of calculations can be encoded into scientific workflows. We believe that AiiDA's design and its sharing capabilities will encourage the creation of social ecosystems to disseminate codes, data, and scientific workflows.},
archivePrefix = {arXiv},
arxivId = {1504.01163},
author = {Pizzi, Giovanni and Cepellotti, Andrea and Sabatini, Riccardo and Marzari, Nicola and Kozinsky, Boris},
doi = {10.1016/j.commatsci.2015.09.013},
eprint = {1504.01163},
file = {:home/martin/Documents/academic/papers{\_}library/Pizzi et al. - 2016 - AiiDA automated interactive infrastructure and database for computational science.pdf:pdf},
issn = {09270256},
journal = {Computational Materials Science},
keywords = {Directed acyclic graph,High-throughput,Materials database,Provenance,Reproducibility,Scientific workflow},
month = {jan},
pages = {218--230},
publisher = {Elsevier B.V.},
title = {{AiiDA: automated interactive infrastructure and database for computational science}},
url = {http://dx.doi.org/10.1016/j.commatsci.2015.09.013 http://linkinghub.elsevier.com/retrieve/pii/S0927025615005820},
volume = {111},
year = {2016}
}

@article{Jain2015b,
abstract = {This paper introduces FireWorks, a workflow software for running high-throughput calculation workflows at supercomputing centers. FireWorks has been used to complete over 50 million CPU-hours worth of computational chemistry and materials science calculations at the National Energy Research Supercomputing Center. It has been designed to serve the demanding high-throughput computing needs of these applications, with extensive support for (i) concurrent execution through job packing, (ii) failure detection and correction, (iii) provenance and reporting for long-running projects, (iv) automated duplicate detection, and (v) dynamic workflows (i.e., modifying the workflow graph during runtime). We have found that these features are highly relevant to enabling modern data-driven and high-throughput science applications, and we discuss our implementation strategy that rests on Python and NoSQL databases (MongoDB). Finally, we present performance data and limitations of our approach along with planned future work.},
author = {Mortensen, Jens and Gjerding, Morten and Thygesen, Kristian},
doi = {10.21105/joss.01844},
file = {:home/martin/Documents/academic/papers{\_}library/Mortensen, Gjerding, Thygesen - 2020 - MyQueue Task and workflow scheduling system.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
keywords = {Fault-tolerant computing,High-throughput computing,Scientific workflows},
month = {jan},
number = {45},
pages = {1844},
title = {{MyQueue: Task and workflow scheduling system}},
url = {https://joss.theoj.org/papers/10.21105/joss.01844},
volume = {5},
year = {2020}
}

@article{Mortensen2020,
author = {Mortensen, Jens and Gjerding, Morten and Thygesen, Kristian},
doi = {10.21105/joss.01844},
file = {:home/martin/Documents/academic/papers{\_}library/Mortensen, Gjerding, Thygesen - 2020 - MyQueue Task and workflow scheduling system.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
keywords = {Fault-tolerant computing,High-throughput computing,Scientific workflows},
month = {jan},
number = {45},
pages = {1844},
title = {{MyQueue: Task and workflow scheduling system}},
url = {https://joss.theoj.org/papers/10.21105/joss.01844},
volume = {5},
year = {2020}
}

@article{Huber2020,
abstract = {The ever-growing availability of computing power and the sustained development of advanced computational methods have contributed much to recent scientific progress. These developments present new challenges driven by the sheer amount of calculations and data to manage. Next-generation exascale supercomputers will harden these challenges, such that automated and scalable solutions become crucial. In recent years, we have been developing AiiDA (http://www.aiida.net), a robust open-source high-throughput infrastructure addressing the challenges arising from the needs of automated workflow management and data provenance recording. Here, we introduce developments and capabilities required to reach sustained performance, with AiiDA supporting throughputs of tens of thousands processes/hour, while automatically preserving and storing the full data provenance in a relational database making it queryable and traversable, thus enabling high-performance data analytics. AiiDA's workflow language provides advanced automation, error handling features and a flexible plugin model to allow interfacing with any simulation software. The associated plugin registry enables seamless sharing of extensions, empowering a vibrant user community dedicated to making simulations more robust, user-friendly and reproducible.},
archivePrefix = {arXiv},
arxivId = {2003.12476},
author = {Huber, Sebastiaan. P. and Zoupanos, Spyros and Uhrin, Martin and Talirz, Leopold and Kahle, Leonid and H{\"{a}}uselmann, Rico and Gresch, Dominik and M{\"{u}}ller, Tiziano and Yakutovich, Aliaksandr V. and Andersen, Casper W. and Ramirez, Francisco F. and Adorf, Carl S. and Gargiulo, Fernando and Kumbhar, Snehal and Passaro, Elsa and Johnston, Conrad and Merkys, Andrius and Cepellotti, Andrea and Mounet, Nicolas and Marzari, Nicola and Kozinsky, Boris and Pizzi, Giovanni},
eprint = {2003.12476},
file = {:home/martin/Documents/academic/papers{\_}library/Huber et al. - 2020 - AiiDA 1.0, a scalable computational infrastructure for automated reproducible workflows and data provenance.pdf:pdf},
title = {{AiiDA 1.0, a scalable computational infrastructure for automated reproducible workflows and data provenance}},
url = {http://arxiv.org/abs/2003.12476},
year = {2020}
}
